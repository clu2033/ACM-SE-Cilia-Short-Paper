\section{Introduction}

Cilia are microtubule-based hair-like projections of cells; in humans, they are found on nearly every cell in the body. Disorders known as ciliopathies, where cilia function is disrupted, can result in a wide spectrum of diseases. In primary ciliary dyskinesia (PCD), airway cilia that normally beat in synchrony to mediate mucus clearance can exhibit dyskinetic motion or become immotile, resulting in severe sinopulmonary disease \cite{o2007diagnosing}. Cilia defects have been associated with increased respiratory complications and poor post-surgical outcomes \cite{nakhleh2012high}. The characterization of cilia abnormalities and specifics of the ciliary motion itself plays a critical role in the identification of specific ciliopathies and the determination of prophylactic respiratory therapies that could improve long-term outcomes in patients. Therefore, an accurate identification of specific ciliary motion patterns is clinically compelling.

An objective, computational method for quantitative assessment of ciliary motion was proposed by Quinn in 2015 \cite{quinn2015automated}. In his work, ciliary motion was considered as an instance of dynamic texture \cite{saisan2001dynamic}. Dynamic textures are modeled as rhythmic motions of particles subjected to stochastic noise \cite{chen2013automatic}. Examples of dynamic textures include familiar motion patterns such as flickering flames, rippling water, and grass in the wind; each containing a small amount of stochastic behavior altering an otherwise regular visual pattern. Ciliary motion is well described as a dynamic texture. This representation proved robust for normal/abnormal binary ciliary motion classification, achieving an accuracy of over 90\% relative to expert ground-truth labeling.

While this study was instrumental in establishing the efficacy of dynamic textures as quantitative representations for ciliary motion, it had some critical limitations, such as the use of autoregressive (AR) models \cite{hyndman2007higher} to model ciliary motion. While AR models are the preferred representation of dynamic textures, their primary usage is in distinguishing between \textit{different} types of dynamic textures, rather than between different instances of the \textit{same} dynamic texture. Furthermore, AR models impose strong parametric assumptions (multivariate Gaussian generating distributions that live on a linear manifold) on the underlying structure of the data  that severely restrict the representative power of the model, truncating their sensitivity to minor yet important variations in motion dynamics and rendering them incapable of capturing complex, nonlinear interactions.

Also, despite considerable effort in automating much of the quantitative motion analysis, the previous work still ultimately relied on expert clinician collaborators to manually select and extract regions of interest (ROI) from the raw video data in order to focus the analysis of the computational pipeline to portions of videos containing cilia. These ROIs potentially introduce the subjective bias of individual preference into the resulting dataset that was used by the AR model.

Here, we examine the application of deep learning, specifically \textit{convolutional neural networks} (CNNs) to perform binary classification on ciliary motion. CNNs do not impose the strong parametric assumptions on the underlying data and can instead capture the complex dynamics and interdependencies through a series of convolutional filters. Furthermore, CNNs do not require manual ROIs to be segmented out and can automatically learn which areas of the videos are relevant to building feature maps. 3D CNNs provide a scalable and automatic solution to ciliary motion classification while still managing to incorporate information about the temporal structure in the video data of cilia biopsies.

\section{Methods}

The objective of this experiment was to establish a baseline accuracy with a deep learning approach to cilia classification. To take advantage of the temporal dimension of video, an artificial neural network with 3D convolution filters was implemented to classify abnormality in ciliary motion. Similar computer vision techniques from previous studies were used to preprocess the raw video data   \cite{quinn2011novel}; specifically, the derivatives of optical flow were computed from the cilia videos and differential flow invariants (rotation) were extracted and fed into the 3D CNN in batches of frame arrays.

The dataset comprised of grayscale videos from nasal brush biopsies on 149 patients and examined by a blinded panel of clinicians. These videos were recorded at 200 frames per second for several seconds and taken at $640 \times 480$ resolution (Fig.~\ref{fig:cilia}). The panel of experts assigned labels to each patient to indicate the degree of abnormal cilia in the videos, where 1 constituted completely normal motion, 4 constituted highly abnormal motion, and 2 and 3 expressed gradations of abnormality. 

\begin{figure}
\includegraphics[scale=0.78]{grey_1011-5_heathly}
\caption{Example frame of a ciliary video labeled as normal; the regions containing cilia are evident along the cell boundaries.}
\label{fig:cilia}
\end{figure}

Multiple videos were collected per patient, and each video was given the label of its patient's label. Some video samples were discarded due to extraneous camera movement, poor lighting, or other recording artifacts. Videos from patients with labels of 2 or 3 were removed from the training set to leave more canonical examples of normal and abnormal motion so that the network could learn better feature maps from more distinctive motion types. Out of the total 325 videos, 266 (81.85\%) canonical videos were used to train the network. From this subset, 127 videos (47.77\%) were labeled as examples of abnormal ciliary motion, while the rest of the videos were labeled as examples of normal motion.
 
Optical flow is used in computer vision to predict the probable motion of pixels between consecutive frames and represents the movements of a pixel as a displacement vector field. Taking linear combinations of the derivatives of optical flow yields differential image invariants, also known as the measures: rotation, divergence, and deformation. These quantities are orientation-invariant which allow ciliary motion to be analyzed irrespective of camera orientation, lighting differences, and even the direction in which the cilia beats~\cite{quinn2015automated}. The computed curl (rotation) of ciliary motion was used for training since it was the only scalar valued component (divergence and deformation being vector quantities). 
 
The videos were standardized to the absolute maximum value in order to preserve the most information of pixel variance when converting from floating point to 16 bit integer data type. Some videos had extremely high maximum values so scalars for each video were individually computed to prevent pixel overflow while preserving the maximum range of the integer data type. Each video had 250 frames that were reduced from $640 \times 480$ to $80 \times 60$ pixels and split into blocks of 10 frames, effectively producing 25 arrays of $80 \times 60 \times 10$ inputs per video. These blocks of arrays were fed in batches of 10 into a 3D CNN which was implemented in TensorFlow and trained on a p2 instance with a NVIDIA K80 GPU from Amazon Web Services (AWS). 

\begin{figure*}
\includegraphics[scale=1.2]{arch}
\caption{Overview of the 3D CNN architecture as implemented in TensorFlow.}
\label{fig:cnn}
\end{figure*}
%\setlength{\textfloatsep}{5pt}

\section{Results}

The 3D CNN architecture had 2 stacked layers, each composed of a 3D convolutional layer, a 3D max pooling layer, and a layer of Rectified-Linear Unit \cite{nair2010rectified} activation functions. These two stacked layers fed into a fully connected dense layer that outputted to a binary softmax classifier. Most CNN ``best'' practices \cite{goodfellow_bengio_courville_2016} were adapted for three dimensions. The first layer had 32 3D convolutional filters and the second layer had 64 filters. The kernel size of each filter was $3 \times 3 \times 3$ with zero padding used and dropout \cite{srivastava2014dropout} added for regularization. The fully connected layer had 57600 weights ($80 * 60 * 10 = 48,000$ plus 9,600 extra weights from the zero padding). A visualization of the network architecture is shown in Fig.~\ref{fig:cnn}.

An adaptive learning rate was used with the ADAM~\cite{kingma2014adam} optimizer. A low batch size of 10 was selected to accommodate the memory capacities of our hardware resources. After 10 iterations, the model converged to a local minimum. We tested classification accuracy with a 66-33\% holdout train-test split. 

The average performance of the 3D CNN on the test set was around 75\%, which is below the 90\% benchmark accuracy from previous work~\cite{quinn2015automated} (Fig.~\ref{fig:iterations}). Using larger batch sizes and pixel dimensions slightly improved performance but at the cost of making the model much more computationally expensive and exhausting the memory capabilities of our machine. Trading dimension size of each frame for a larger block size had little effect in terms of accuracy but also greatly increased computational requirements.  

\begin{figure}
\includegraphics[scale=0.5]{CNN_graph}
\caption{Training and testing accuracy of the 3D CNN as a function of network epochs.}
\label{fig:iterations}
%\setlength{\belowcaptionskip}{-10pt}

\end{figure}


\section{Discussion}

Clearly, the model is severely overfitting the current dataset. Several regularization techniques could be implemented to combat this: transfer learning from pre-trained networks, data augmentation, and batch normalization. However, each pose their own difficulties. For transfer learning \cite{pan2010survey}, most pre-trained network weights are currently designed for image rather than video data. While data augmentation is feasible, transformations must be done congruently within batches to maintain the temporal structure and would require more processing power for videos than images when done in memory. Also, the underlying structure of the processed rotation data might not allow for the same transformations as the original grayscale videos. Batch Normalization \cite{ioffe2015batch} would be straightforward enough to implement but seems unlikely to improve current classification accuracy to the state of the art benchmark. Insight from already experimenting with the dropout regularization parameter suggests that the learning capacity of the 3D CNN is too complex to extract good feature maps from the down-sampled data. We believe a better solution would be to provide the network with more labeled training examples and enough computing resources to allow for larger input size dimensions. 
 
A limitation of the current dataset is each video takes the label at a patient level instead of the video level itself, which might not contain any abnormal motion despite the patient being labeled as abnormal or vise versa. Also, a training example might contain multiple cells with some cells showing normal motion while others showing abnormal motion in the same video which complicates training. We attempted to mitigate this effect of misleading examples by following Bengio's \cite{bengio2009curriculum} principle of curriculum learning, opting to train only on patients labeled 1 and 4 (trading quantity of training examples for more canonical and distinct motion examples).

Another limitation was the drastic reduction in cilia video dimensions. The processed videos had to be reduced to $\frac{1}{8}$ their original size to remain within the bounds of our server's memory limits. This downsampling greatly diminished the network's capacity to extract relevant features and to discriminate between normal and abnormal motion. With more computing resources and a more precisely labeled dataset, we expect increased classification accuracy with the 3D CNN model. With additional preprocessing, the deformation vector data could also be incorporated with the rotation data to provide even more contextual information for network to learn better representations about the dynamics of ciliary motion.

\section{Conclusion}

Although deep learning methods usually require an abundant amount of labeled training data, one possible way to circumvent this issue would be to train another CNN to automatically generate a heat-map of candidate areas of videos where cilia are likely to be present, similar to the deep learning pipeline \cite{wang2016deep} that won the Camelyon 17 challenge for breast cancer classification. These candidate areas would then be fed into another classifier such as a Gradient Boosted Decision Tree or even another CNN to predict the probability of abnormal cilia in that region.
 
Other approaches that could leverage deep learning for cilia classification are Recurrent Neural Networks (RNNs) such as the Long-Short Term Memory (LSTM) network, which inherently incorporates the dimension of time to build feature maps. It is even possible to stack CNNs on top of RNNs to leverage aspects of both network architecture types. Other researchers \cite{sonderby2015convolutional} have already applied a similar approach with excellent results on the localization of protein structures. Another interesting area of deep learning that also presents a promising approach to solving the broader problems of cilia segmentation and identification of different cilia motion phenotypes (both normal and abnormal) include the attention-seeking mechanisms of RNNs and General Adversarial Networks (GAN). Attention mechanisms and GANs could be used to segment out cilia and to generate a canonical phenotype of a specific ciliary motion, respectively.

\section{Acknowledgements}

The authors would like to acknowledge the University of Pittsburgh and Children's Hospital of the University of Pittsburgh Medical Center for initial acquisition of video microscopy data. In particular, we would like to acknowledge and thank Dr. Chakra Chennubhotla, Dr. Maliha Zahid, and Dr. Cecilia Lo.


%\end{document}  % This is where a 'short' article might terminate
